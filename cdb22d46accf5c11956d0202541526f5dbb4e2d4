{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "7c762249_c0684019",
        "filename": "/COMMIT_MSG",
        "patchSetId": 6
      },
      "lineNbr": 10,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-10-29T15:59:21Z",
      "side": 1,
      "message": "It isn\u0027t really a \"maximising\" thing but rather a requirement. If you have the two containers in HA being placed into the same EC2 instance on the same AZ, then it is clearly not HA at all, because the failure of the node OR the AZ would cause an outage.",
      "range": {
        "startLine": 10,
        "startChar": 9,
        "endLine": 10,
        "endChar": 17
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "47fa8b24_65eae785",
        "filename": "/COMMIT_MSG",
        "patchSetId": 6
      },
      "lineNbr": 10,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-10-29T16:48:09Z",
      "side": 1,
      "message": "you\u0027re right.\nThe thing is that at the moment the entire deployment of aws-gerrit happens on one *AZ* only, and it is not possible to configure otherwise, unless we start introducing the concept of subnet*s* into it.\n\nI think it should be done and perhaps we need additional issues to capture this need.\n\nAs far as this change is concerned, perhaps I can phrase it as \"...in order to increase Gerrit reliability...\"\n\nWDYT?",
      "parentUuid": "7c762249_c0684019",
      "range": {
        "startLine": 10,
        "startChar": 9,
        "endLine": 10,
        "endChar": 17
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "4a391ecd_866ec026",
        "filename": "/COMMIT_MSG",
        "patchSetId": 6
      },
      "lineNbr": 10,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-10-29T17:16:35Z",
      "side": 1,
      "message": "Also in a single AZ, having both masters on the same EC2 instance isn\u0027t assuring any HA. It is more for \"assuring\" rather than increasing or maximising.",
      "parentUuid": "47fa8b24_65eae785",
      "range": {
        "startLine": 10,
        "startChar": 9,
        "endLine": 10,
        "endChar": 17
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "d347ad67_b3c0315e",
        "filename": "/COMMIT_MSG",
        "patchSetId": 6
      },
      "lineNbr": 10,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-10-29T17:57:33Z",
      "side": 1,
      "message": "Ack",
      "parentUuid": "4a391ecd_866ec026",
      "range": {
        "startLine": 10,
        "startChar": 9,
        "endLine": 10,
        "endChar": 17
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "1b614d56_7b915ce5",
        "filename": "/COMMIT_MSG",
        "patchSetId": 6
      },
      "lineNbr": 10,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-10-30T23:37:03Z",
      "side": 1,
      "message": "Did you forget to apply the changes?",
      "parentUuid": "d347ad67_b3c0315e",
      "range": {
        "startLine": 10,
        "startChar": 9,
        "endLine": 10,
        "endChar": 17
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "b1e4eb12_933c013a",
        "filename": "/COMMIT_MSG",
        "patchSetId": 6
      },
      "lineNbr": 10,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-11-02T10:01:08Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "1b614d56_7b915ce5",
      "range": {
        "startLine": 10,
        "startChar": 9,
        "endLine": 10,
        "endChar": 17
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7756bed4_8f0c53ba",
        "filename": "/COMMIT_MSG",
        "patchSetId": 6
      },
      "lineNbr": 14,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-10-29T15:59:21Z",
      "side": 1,
      "message": "Isn\u0027t that more for the LB vs. master node problem rather than having true HA with the separation of the two EC2 instances?",
      "range": {
        "startLine": 12,
        "startChar": 0,
        "endLine": 14,
        "endChar": 68
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8489d864_cea2c6f1",
        "filename": "/COMMIT_MSG",
        "patchSetId": 6
      },
      "lineNbr": 14,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-10-29T16:48:09Z",
      "side": 1,
      "message": "I think it is both: separating ha-proxies from masters obtains two gains\n- Increasing HA\n- Allowing ha-proxies to always talk to both masters rather than just the one deployed on a different instance.",
      "parentUuid": "7756bed4_8f0c53ba",
      "range": {
        "startLine": 12,
        "startChar": 0,
        "endLine": 14,
        "endChar": 68
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0c552d04_19698d80",
        "filename": "/COMMIT_MSG",
        "patchSetId": 6
      },
      "lineNbr": 14,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-10-29T17:16:35Z",
      "side": 1,
      "message": "Gotcha, but your phrase is again about the L4 networking issue. I agree more with your two gains, because the L4 networking issue has been already resolved by  Change-Id: I38ad5d2.\n\nCan you align the commit message with your explanation? Which makes a lot of sense to me :-)",
      "parentUuid": "8489d864_cea2c6f1",
      "range": {
        "startLine": 12,
        "startChar": 0,
        "endLine": 14,
        "endChar": 68
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "e0df1d6d_112a62f4",
        "filename": "/COMMIT_MSG",
        "patchSetId": 6
      },
      "lineNbr": 14,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-10-29T17:57:33Z",
      "side": 1,
      "message": "Ack",
      "parentUuid": "0c552d04_19698d80",
      "range": {
        "startLine": 12,
        "startChar": 0,
        "endLine": 14,
        "endChar": 68
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b1f40581_c12e30a8",
        "filename": "/COMMIT_MSG",
        "patchSetId": 6
      },
      "lineNbr": 14,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-11-02T12:39:48Z",
      "side": 1,
      "message": "Still forgot to push? I still see the L4 networking thing: this change is about separating masters, correct? The HAProxy cluster has been already put onto a separate ASG, so it should be fixed right now.",
      "parentUuid": "e0df1d6d_112a62f4",
      "range": {
        "startLine": 12,
        "startChar": 0,
        "endLine": 14,
        "endChar": 68
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "3374e204_624d9885",
        "filename": "/COMMIT_MSG",
        "patchSetId": 6
      },
      "lineNbr": 14,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-11-02T13:01:04Z",
      "side": 1,
      "message": "Yes, I am sorry luca, I got two changes mixed up: this is not at all about ha-proxies.\n\nit should *actually* be fixed now ðŸ˜Š",
      "parentUuid": "b1f40581_c12e30a8",
      "range": {
        "startLine": 12,
        "startChar": 0,
        "endLine": 14,
        "endChar": 68
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "d1059a2d_af2dfe61",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-10-29T15:59:21Z",
      "side": 1,
      "message": "It looks like we are forcing the cluster to be fixed at 1x EC2 instance, instead of having a parametrised capacity.",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "dcf4c395_3d9899be",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-10-29T16:48:09Z",
      "side": 1,
      "message": "I think the \"desired number of instances\" made sense before because we had to accommodate multiple instances in one ASG only.\n\nBut this is not the case anymore, we have different ASGs for different components and master1 and master2 will always take one and exactly one ec2 instance.\nMasters cannot elastically scale out, that\u0027s why we explicitly configure master1 and master2 from the setup.env down to the cf templates.\n\nWhat would mean to have a desired cluster of 3 for the master1 ASG?",
      "parentUuid": "d1059a2d_af2dfe61",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "a3878f5e_12bdd773",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-10-29T17:16:35Z",
      "side": 1,
      "message": "If that was the case, why we didn\u0027t have a fixed number of EC2 instances before?\nAlso, the ASG is for the EC2 instances of the ECS cluster, and not for *exclusively* the master node.\n\nI don\u0027t believe that removing a parameter that we have now for then introducing it again in the next change is a good thing, but rather a regression IMHO.",
      "parentUuid": "dcf4c395_3d9899be",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "ab51059f_284bceeb",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-10-29T17:57:33Z",
      "side": 1,
      "message": "\u003e If that was the case, why we didn\u0027t have a fixed number of EC2 instances before?\n\nBecause depending on the spec of Gerrit you might have wanted/needed more EC2 instances to host them:\n- If you deployed masters with very low ram/cpu needs, for example, then perhaps 2 instances would have been enough (to host masters,haproxy,slaves), whilst if you needed more resources for Gerrit, you might have wanted more ec2 instances to allow them to be allocated.\n\n\u003e Also, the ASG is for the EC2 instances of the ECS cluster, and not for *exclusively* the master node.\n\nNot anymore, we have 3 ASGs in the cluster at the moment (master, replica, haproxy) and the \"desired number of instances\" is not a property of the ECS cluster, but rather a property of the ASG.\n\nThere are 3 different ASG that could potentially be tuned with [min-desired-max], one for each ASG.\n\n* haproxy -\u003e this should go to a 2-2-n (as per your point in the previous CR, I will raise the relevant change)\n* master -\u003e this should be 1-1-1, always, because masters cannot scale.\n* replica -\u003e this should be 1-1-1 until we introduce EFS that allow them to scale.\n\nWDYT?",
      "parentUuid": "a3878f5e_12bdd773",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7372e1b8_b8275fe1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-10-29T20:35:48Z",
      "side": 1,
      "message": "\u003e \u003e If that was the case, why we didn\u0027t have a fixed number of EC2 instances before?\n\u003e \n\u003e Because depending on the spec of Gerrit you might have wanted/needed more EC2 instances to host them:\n\u003e - If you deployed masters with very low ram/cpu needs, for example, then perhaps 2 instances would have been enough (to host masters,haproxy,slaves), whilst if you needed more resources for Gerrit, you might have wanted more ec2 instances to allow them to be allocated.\n\nI don\u0027t get it. If you had two masters, how allocating 6 EC2 would have given more resources?\n\nI believe before it was more forward thinking, allowing the next iterations of this recipe to have more horsepower. Remember that we still need to add additional components:\n- Git daemon\n- Git/SSH\n- JGit GC node\n\n\u003e \u003e Also, the ASG is for the EC2 instances of the ECS cluster, and not for *exclusively* the master node.\n\u003e \n\u003e Not anymore, we have 3 ASGs in the cluster at the moment (master, replica, haproxy) and the \"desired number of instances\" is not a property of the ECS cluster, but rather a property of the ASG.\n\nAren\u0027t the 3 ASGs part of the ECS cluster, just with different labels?\nWe can of course have 2 settings now:\n- Desired number of masters\u0027 EC2 instances\n- Desired number of WLB EC2 instances\n\nDepending on how many many containers you want in each ASG, you may want different number of instances.\n\n\u003e There are 3 different ASG that could potentially be tuned with [min-desired-max], one for each ASG.\n\u003e \n\u003e * haproxy -\u003e this should go to a 2-2-n (as per your point in the previous CR, I will raise the relevant change)\n\nN should be configurable\n\n\u003e * master -\u003e this should be 1-1-1, always, because masters cannot scale.\n\nNope, you would need extra horsepower for additional components, as I mentioned.\nAlso, when you do blue/green deployments, I imagine that ECS would do:\na. Create the new task\nb. Wait for the task to be healthy\nc. Kill the old task\n\nIf you have only 1 fixed EC2 instance, it may actually fail to do the upgrades with blue/green deployments.\n\n\u003e * replica -\u003e this should be 1-1-1 until we introduce EFS that allow them to scale.\n\nWhy? Replicas are intended to be scaled up, as they are stateless. This is exactly the point where we want to have the maximum number of instances as a parameter.\n\nWe do have already the parameter for allowing them to scale up, I can understand the point of making it 3 parameters, which is fair. I don\u0027t get the point of hardcoding the maximum values, as they are not hardcoded now.",
      "parentUuid": "ab51059f_284bceeb",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "eb656d7e_2a17c3bb",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-10-30T09:44:30Z",
      "side": 1,
      "message": "\u003e \u003e \u003e If that was the case, why we didn\u0027t have a fixed number of EC2 instances before?\n\u003e \u003e \n\u003e \u003e Because depending on the spec of Gerrit you might have wanted/needed more EC2 instances to host them:\n\u003e \u003e - If you deployed masters with very low ram/cpu needs, for example, then perhaps 2 instances would have been enough (to host masters,haproxy,slaves), whilst if you needed more resources for Gerrit, you might have wanted more ec2 instances to allow them to be allocated.\n\u003e \n\u003e I don\u0027t get it. If you had two masters, how allocating 6 EC2 would have given more resources?\n\n\n\nImagine these are the specs defined for your deployment\n\n* Master Service *\nGerrit:\n- Memory: 6Gb\n- Cpu: 1024 (1 vCPU)\n\n* Replica Service *\nGerrit:\n- Memory: 6Gb\n- Cpu: 1024 (1 vCPU)\n\nGit daemon:\n- Memory: 512Mb\n- Cpu: 256 (0.25 vCPU)\n\nGit SSH:\n- Memory: 512Mb\n- Cpu: 256 (0.25 vCPU)\n\n* Loadbalancer service *\n\nha-proxy:\n- Memory: 2Gb\n- Cpu: 1024 (1 vCPU)\n\nTotal Memory needed: (6Gb x 2) + (6Gb + 512Mb + 512Mb) + 2Gb \u003d 19Gb\nTotal CPU needed:   (1024 x 2) + (1024 + 256 + 256)    + 1024 \u003d 4608 (~ 5vCPUs)\n\nNow, let\u0027s assume your you have chosen a cluster EC2 instance type of\n\nm4.xlarge: 4 vCPUs, 16 Gb RAM\n\nYou will need a desired number of instances of _at least_ \u00272\u0027: if you had \u00271\u0027 you wouldn\u0027t have room for 19Gb and 5 vCPUs.\n\nIf you changed your gerrit specs to be higher however, you might need a cluster of 3, and so on.\n\nThe number of instances in the cluster is a function of _needed resources_, not just of _number of instances_.\n\n\n\n\n\n\u003e \n\u003e I believe before it was more forward thinking, allowing the next iterations of this recipe to have more horsepower. Remember that we still need to add additional components:\n\u003e - Git daemon\n\u003e - Git/SSH\n\n\n\n^^^ These are already part of the replica service\n\n\n\n\n\u003e - JGit GC node\n\n\n\nNot sure this one will need to be a component: it is an operational task and it could be modelled as a ECS daemon[1], or a step function, or SSM, or a lambda, etc.\n\n\n\n\u003e \n\u003e \u003e \u003e Also, the ASG is for the EC2 instances of the ECS cluster, and not for *exclusively* the master node.\n\u003e \u003e \n\u003e \u003e Not anymore, we have 3 ASGs in the cluster at the moment (master, replica, haproxy) and the \"desired number of instances\" is not a property of the ECS cluster, but rather a property of the ASG.\n\u003e \n\u003e Aren\u0027t the 3 ASGs part of the ECS cluster, just with different labels?\n\nYes, they are 3 ASGs _registered_ to the same ECS cluster.\n\n\u003e We can of course have 2 settings now:\n\u003e - Desired number of masters\u0027 EC2 instances\n\u003e - Desired number of WLB EC2 instances\n\n\n\nWhat\u0027s a WLB? Worker?\n\n\n\n\n\u003e \n\u003e Depending on how many many containers you want in each ASG, you may want different number of instances.\n\u003e \n\u003e \u003e There are 3 different ASG that could potentially be tuned with [min-desired-max], one for each ASG.\n\u003e \u003e \n\u003e \u003e * haproxy -\u003e this should go to a 2-2-n (as per your point in the previous CR, I will raise the relevant change)\n\u003e \n\u003e N should be configurable\n\n\n\nYes agreed, I\u0027ll raise an issue for this.\n\n\n\n\n\u003e \n\u003e \u003e * master -\u003e this should be 1-1-1, always, because masters cannot scale.\n\u003e \n\u003e Nope, you would need extra horsepower for additional components, as I mentioned.\n\n\nI believe the extra components are there already (if you mean the ones for replicas). If not, which other components do you mean?\n\n\n\u003e Also, when you do blue/green deployments, I imagine that ECS would do:\n\u003e a. Create the new task\n\u003e b. Wait for the task to be healthy\n\u003e c. Kill the old task\n\u003e \n\u003e If you have only 1 fixed EC2 instance, it may actually fail to do the upgrades with blue/green deployments.\n\u003e \n\u003e \u003e * replica -\u003e this should be 1-1-1 until we introduce EFS that allow them to scale.\n\u003e \n\u003e Why? Replicas are intended to be scaled up, as they are stateless. This is exactly the point where we want to have the maximum number of instances as a parameter.\n\u003e \n\u003e We do have already the parameter for allowing them to scale up, I can understand the point of making it 3 parameters, which is fair. I don\u0027t get the point of hardcoding the maximum values, as they are not hardcoded now.\n\n\n\n\n\nLet\u0027s say we scaled replicas to 3 instances.\nNow we have a NLB, with a targetGroup containing 3 replicas running on 3 different EC2 instances, each one having its own independent git data (on EBS).\n\nWhen masters replicate to the replica NLB, only _one_ of the 3 will receive the update, leaving the other ones behind.\n\nWhat\u0027s the point of increasing the number of replicas before we have an EFS to share across them?\n\n\n[1] https://aws.amazon.com/about-aws/whats-new/2018/06/amazon-ecs-adds-daemon-scheduling/",
      "parentUuid": "7372e1b8_b8275fe1",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "90ff421e_43ed4ef0",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-11-02T12:39:48Z",
      "side": 1,
      "message": "\u003e \u003e \u003e \u003e If that was the case, why we didn\u0027t have a fixed number of EC2 instances before?\n\u003e \u003e \u003e \n\u003e \u003e \u003e Because depending on the spec of Gerrit you might have wanted/needed more EC2 instances to host them:\n\u003e \u003e \u003e - If you deployed masters with very low ram/cpu needs, for example, then perhaps 2 instances would have been enough (to host masters,haproxy,slaves), whilst if you needed more resources for Gerrit, you might have wanted more ec2 instances to allow them to be allocated.\n\u003e \u003e \n\u003e \u003e I don\u0027t get it. If you had two masters, how allocating 6 EC2 would have given more resources?\n\u003e \n\u003e \n\u003e \n\u003e Imagine these are the specs defined for your deployment\n\u003e \n\u003e * Master Service *\n\u003e Gerrit:\n\u003e - Memory: 6Gb\n\u003e - Cpu: 1024 (1 vCPU)\n\u003e \n\u003e * Replica Service *\n\u003e Gerrit:\n\u003e - Memory: 6Gb\n\u003e - Cpu: 1024 (1 vCPU)\n\u003e \n\u003e Git daemon:\n\u003e - Memory: 512Mb\n\u003e - Cpu: 256 (0.25 vCPU)\n\u003e \n\u003e Git SSH:\n\u003e - Memory: 512Mb\n\u003e - Cpu: 256 (0.25 vCPU)\n\u003e \n\u003e * Loadbalancer service *\n\u003e \n\u003e ha-proxy:\n\u003e - Memory: 2Gb\n\u003e - Cpu: 1024 (1 vCPU)\n\u003e \n\u003e Total Memory needed: (6Gb x 2) + (6Gb + 512Mb + 512Mb) + 2Gb \u003d 19Gb\n\u003e Total CPU needed:   (1024 x 2) + (1024 + 256 + 256)    + 1024 \u003d 4608 (~ 5vCPUs)\n\u003e \n\u003e Now, let\u0027s assume your you have chosen a cluster EC2 instance type of\n\u003e \n\u003e m4.xlarge: 4 vCPUs, 16 Gb RAM\n\u003e \n\u003e You will need a desired number of instances of _at least_ \u00272\u0027: if you had \u00271\u0027 you wouldn\u0027t have room for 19Gb and 5 vCPUs.\n\nIf you needed resources for 5 containers, how 6 instances could have helped out?\nI do not believe AWS can split a container across multiple EC2 instances, to provide more resources.\n\n\u003e If you changed your gerrit specs to be higher however, you might need a cluster of 3, and so on.\n\u003e \n\u003e The number of instances in the cluster is a function of _needed resources_, not just of _number of instances_.\n\nI am not 100% convinced AWS can do that, also inside an ECS cluster.\nAt the end of the day, ECS is just an orchestrator of Docker containers, and the minimum allocation is 1 container per instance, but won\u0027t be able to go beyond that. The maximum allocation instead would be all containers in a single instance.\n\n\u003e \u003e I believe before it was more forward thinking, allowing the next iterations of this recipe to have more horsepower. Remember that we still need to add additional components:\n\u003e \u003e - Git daemon\n\u003e \u003e - Git/SSH\n\u003e ^^^ These are already part of the replica service\n\nAck. So the replica service should have a number of configurable instances, correct? With a maximum of 2.\n\n\u003e \u003e - JGit GC node\n\u003e \n\u003e Not sure this one will need to be a component: it is an operational task and it could be modelled as a ECS daemon[1], or a step function, or SSM, or a lambda, etc.\n\nAn ECS daemon would still need to be allocated in the cluster with some placement, correct?\n\nAn AWS step function is just an orchestration of something, not really a computing entity whilst with the AWS lambdas, I\u0027m not 100% sure they are designed to run a long, CPU and memory intensive operation, like the JGit GC.\n\n\u003e \u003e \n\u003e \u003e \u003e \u003e Also, the ASG is for the EC2 instances of the ECS cluster, and not for *exclusively* the master node.\n\u003e \u003e \u003e \n\u003e \u003e \u003e Not anymore, we have 3 ASGs in the cluster at the moment (master, replica, haproxy) and the \"desired number of instances\" is not a property of the ECS cluster, but rather a property of the ASG.\n\u003e \u003e \n\u003e \u003e Aren\u0027t the 3 ASGs part of the ECS cluster, just with different labels?\n\u003e \n\u003e Yes, they are 3 ASGs _registered_ to the same ECS cluster.\n\u003e \n\u003e \u003e We can of course have 2 settings now:\n\u003e \u003e - Desired number of masters\u0027 EC2 instances\n\u003e \u003e - Desired number of WLB EC2 instances\n\u003e \n\u003e What\u0027s a WLB? Worker?\n\nWLB \u003d Workload Balancer \u003d HA Proxy\n\n\u003e \u003e Depending on how many many containers you want in each ASG, you may want different number of instances.\n\u003e \u003e \n\u003e \u003e \u003e There are 3 different ASG that could potentially be tuned with [min-desired-max], one for each ASG.\n\u003e \u003e \u003e \n\u003e \u003e \u003e * haproxy -\u003e this should go to a 2-2-n (as per your point in the previous CR, I will raise the relevant change)\n\u003e \u003e \n\u003e \u003e N should be configurable\n\u003e \n\u003e Yes agreed, I\u0027ll raise an issue for this.\n\n+1\n\n\u003e \u003e \n\u003e \u003e \u003e * master -\u003e this should be 1-1-1, always, because masters cannot scale.\n\u003e \u003e \n\u003e \u003e Nope, you would need extra horsepower for additional components, as I mentioned.\n\u003e \n\u003e \n\u003e I believe the extra components are there already (if you mean the ones for replicas). If not, which other components do you mean?\n\nE.g. I am not sure how would you do upgrades without having the ability to scale, isn\u0027t it? Or does ECS already increase the ASG to 2 for upgrades? Also, see the JGit GC discussion, that would need some node allocation somewhere anyway.\n\n\u003e Let\u0027s say we scaled replicas to 3 instances.\n\u003e Now we have a NLB, with a targetGroup containing 3 replicas running on 3 different EC2 instances, each one having its own independent git data (on EBS).\n\u003e \n\u003e When masters replicate to the replica NLB, only _one_ of the 3 will receive the update, leaving the other ones behind.\n\nNope, when you have replicas with ASG they need to share the repositories, otherwise when they scale up then won\u0027t have the latest version of the repositories.\n\n\u003e What\u0027s the point of increasing the number of replicas before we have an EFS to share across them?\n\nHorizontal scalability, for managing peaks of incoming traffic.\n\n\u003e [1] https://aws.amazon.com/about-aws/whats-new/2018/06/amazon-ecs-adds-daemon-scheduling/",
      "parentUuid": "eb656d7e_2a17c3bb",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9cef0b1d_9e8c529e",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-11-02T13:47:13Z",
      "side": 1,
      "message": "Hey Luca, sorry for top posting here, but the conversation is getting quite nested and I start struggling to find the inline replies, feel free to re-compact this if you feel like.\n\nMeanwhile, my replies in-line ðŸ˜Š\n\n\n\n\u003e \u003e \u003e \u003e \u003e If that was the case, why we didn\u0027t have a fixed number of EC2 instances before?\n\u003e \u003e \u003e \u003e \n\u003e \u003e \u003e \u003e Because depending on the spec of Gerrit you might have wanted/needed more EC2 instances to host them:\n\u003e \u003e \u003e \u003e - If you deployed masters with very low ram/cpu needs, for example, then perhaps 2 instances would have been enough (to host masters,haproxy,slaves), whilst if you needed more resources for Gerrit, you might have wanted more ec2 instances to allow them to be allocated.\n\u003e \u003e \u003e \n\u003e \u003e \u003e I don\u0027t get it. If you had two masters, how allocating 6 EC2 would have given more resources?\n\u003e \u003e \n\u003e \u003e \n\u003e \u003e \n\u003e \u003e Imagine these are the specs defined for your deployment\n\u003e \u003e \n\u003e \u003e * Master Service *\n\u003e \u003e Gerrit:\n\u003e \u003e - Memory: 6Gb\n\u003e \u003e - Cpu: 1024 (1 vCPU)\n\u003e \u003e \n\u003e \u003e * Replica Service *\n\u003e \u003e Gerrit:\n\u003e \u003e - Memory: 6Gb\n\u003e \u003e - Cpu: 1024 (1 vCPU)\n\u003e \u003e \n\u003e \u003e Git daemon:\n\u003e \u003e - Memory: 512Mb\n\u003e \u003e - Cpu: 256 (0.25 vCPU)\n\u003e \u003e \n\u003e \u003e Git SSH:\n\u003e \u003e - Memory: 512Mb\n\u003e \u003e - Cpu: 256 (0.25 vCPU)\n\u003e \u003e \n\u003e \u003e * Loadbalancer service *\n\u003e \u003e \n\u003e \u003e ha-proxy:\n\u003e \u003e - Memory: 2Gb\n\u003e \u003e - Cpu: 1024 (1 vCPU)\n\u003e \u003e \n\u003e \u003e Total Memory needed: (6Gb x 2) + (6Gb + 512Mb + 512Mb) + 2Gb \u003d 19Gb\n\u003e \u003e Total CPU needed:   (1024 x 2) + (1024 + 256 + 256)    + 1024 \u003d 4608 (~ 5vCPUs)\n\u003e \u003e \n\u003e \u003e Now, let\u0027s assume your you have chosen a cluster EC2 instance type of\n\u003e \u003e \n\u003e \u003e m4.xlarge: 4 vCPUs, 16 Gb RAM\n\u003e \u003e \n\u003e \u003e You will need a desired number of instances of _at least_ \u00272\u0027: if you had \u00271\u0027 you wouldn\u0027t have room for 19Gb and 5 vCPUs.\n\u003e \n\u003e If you needed resources for 5 containers, how 6 instances could have helped out?\n\n\n\n\n\nThey wouldn\u0027t, of course, because you have EC2 instances that you would never be able to use (unless you start scaling).\nBut you were able to decide if you wanted those 5 instances over 3 m4.xlarge or over 2 m4.2xlarge, for example.\n\n\n\n\n\u003e I do not believe AWS can split a container across multiple EC2 instances, to provide more resources.\n\n\n\n\nThe most granular component that can be deployed is not the container, it\u0027s the task.\n\n* ECS Instance -\u003e EC2 instance with an ecs-agent running on it.\n* Service -\u003e collection of Tasks\n* Task -\u003e collection of Containers (replica task for example is composed by gerrit/ssh/daemon)\n\nWhilst the service can span across multiple ECS Instances, the Task cannot and it is always deployed in the same ECS Instance.\n\n\n\n\n\n\n\n\u003e \n\u003e \u003e If you changed your gerrit specs to be higher however, you might need a cluster of 3, and so on.\n\u003e \u003e \n\u003e \u003e The number of instances in the cluster is a function of _needed resources_, not just of _number of instances_.\n\u003e \n\u003e I am not 100% convinced AWS can do that, also inside an ECS cluster.\n\u003e At the end of the day, ECS is just an orchestrator of Docker containers, and the minimum allocation is 1 container per instance, but won\u0027t be able to go beyond that. The maximum allocation instead would be all containers in a single instance.\n\n\n\n\nThe minimum allocation is 1 _Task_ per instance, not 1 container.\nThe most compact allocation is all _Services_ in a single instance (but as we have seen we cannot have this topology because tasks wouldn\u0027t be able to talk to each others via the NLB).\n\n\n\n\n\u003e \n\u003e \u003e \u003e I believe before it was more forward thinking, allowing the next iterations of this recipe to have more horsepower. Remember that we still need to add additional components:\n\u003e \u003e \u003e - Git daemon\n\u003e \u003e \u003e - Git/SSH\n\u003e \u003e ^^^ These are already part of the replica service\n\u003e \n\u003e Ack. So the replica service should have a number of configurable instances, correct? With a maximum of 2.\n\u003e \n\u003e \u003e \u003e - JGit GC node\n\u003e \u003e \n\u003e \u003e Not sure this one will need to be a component: it is an operational task and it could be modelled as a ECS daemon[1], or a step function, or SSM, or a lambda, etc.\n\u003e \n\u003e An ECS daemon would still need to be allocated in the cluster with some placement, correct?\n\u003e \n\u003e An AWS step function is just an orchestration of something, not really a computing entity whilst with the AWS lambdas, I\u0027m not 100% sure they are designed to run a long, CPU and memory intensive operation, like the JGit GC.\n\n\n\n\n\nAs I was mentioning, I am not sure, I think there are different approaches, some of which do not need any additional allocation (SSM agent[1] already runs on Amazon Linux images, so it could be \"talked to\" without running extra components).\nShall we discuss/brainstorm about this specific issue in the relevant issue ticket?[2]\n\n\n\u003e \n\u003e \u003e \u003e \n\u003e \u003e \u003e \u003e \u003e Also, the ASG is for the EC2 instances of the ECS cluster, and not for *exclusively* the master node.\n\u003e \u003e \u003e \u003e \n\u003e \u003e \u003e \u003e Not anymore, we have 3 ASGs in the cluster at the moment (master, replica, haproxy) and the \"desired number of instances\" is not a property of the ECS cluster, but rather a property of the ASG.\n\u003e \u003e \u003e \n\u003e \u003e \u003e Aren\u0027t the 3 ASGs part of the ECS cluster, just with different labels?\n\u003e \u003e \n\u003e \u003e Yes, they are 3 ASGs _registered_ to the same ECS cluster.\n\u003e \u003e \n\u003e \u003e \u003e We can of course have 2 settings now:\n\u003e \u003e \u003e - Desired number of masters\u0027 EC2 instances\n\u003e \u003e \u003e - Desired number of WLB EC2 instances\n\u003e \u003e \n\u003e \u003e What\u0027s a WLB? Worker?\n\u003e \n\u003e WLB \u003d Workload Balancer \u003d HA Proxy\n\n+1\n\n\u003e \n\u003e \u003e \u003e Depending on how many many containers you want in each ASG, you may want different number of instances.\n\u003e \u003e \u003e \n\u003e \u003e \u003e \u003e There are 3 different ASG that could potentially be tuned with [min-desired-max], one for each ASG.\n\u003e \u003e \u003e \u003e \n\u003e \u003e \u003e \u003e * haproxy -\u003e this should go to a 2-2-n (as per your point in the previous CR, I will raise the relevant change)\n\u003e \u003e \u003e \n\u003e \u003e \u003e N should be configurable\n\u003e \u003e \n\u003e \u003e Yes agreed, I\u0027ll raise an issue for this.\n\u003e \n\u003e +1\n\n\nDone: https://gerrit-review.googlesource.com/c/aws-gerrit/+/286280\n\n\u003e \n\u003e \u003e \u003e \n\u003e \u003e \u003e \u003e * master -\u003e this should be 1-1-1, always, because masters cannot scale.\n\u003e \u003e \u003e \n\u003e \u003e \u003e Nope, you would need extra horsepower for additional components, as I mentioned.\n\u003e \u003e \n\u003e \u003e \n\u003e \u003e I believe the extra components are there already (if you mean the ones for replicas). If not, which other components do you mean?\n\u003e \n\u003e E.g. I am not sure how would you do upgrades without having the ability to scale, isn\u0027t it? Or does ECS already increase the ASG to 2 for upgrades? Also, see the JGit GC discussion, that would need some node allocation somewhere anyway.\n\u003e \n\n\n\n\n\n\n\nScaling for \"more horsepower\" for masters is something I don\u0027t get, masters only run gerrit masters and I am not convinced we need to run anything else alongside them (at least for now).\n\nRolling upgrades is an interesting subject and you\u0027re right, it might fall into the same conversation.\n\nTBH, I was thinking something along the lines of\n- deploy a completely new green cluster (maintaining the data)\n- Switch traffic to green\n- delete blue cluster\n\nWere you thinking about scaling up the blue cluster and let old and new co-living together in the same cluster?\n\nP.S. Should I create a monorail ticket to address upgrades?\n\n\n\n\n\n\n\n\u003e \u003e Let\u0027s say we scaled replicas to 3 instances.\n\u003e \u003e Now we have a NLB, with a targetGroup containing 3 replicas running on 3 different EC2 instances, each one having its own independent git data (on EBS).\n\u003e \u003e \n\u003e \u003e When masters replicate to the replica NLB, only _one_ of the 3 will receive the update, leaving the other ones behind.\n\u003e \n\u003e Nope, when you have replicas with ASG they need to share the repositories, otherwise when they scale up then won\u0027t have the latest version of the repositories.\n\n\n\n\n\n\nExactly, they need to share the repositories, but they just don\u0027t do that at the moment.\nThat\u0027s why I was asking \"What\u0027s the point of increasing the number of replicas _before we have an EFS to share across them?_\"\n\nI understand the benefit of scaling replicas _once_ they share repositories.\n\n\n\n\n\u003e \n\u003e \u003e What\u0027s the point of increasing the number of replicas before we have an EFS to share across them?\n\u003e \n\u003e Horizontal scalability, for managing peaks of incoming traffic.\n\n\n\n\nI understand why we need to scale replicas, of course.\nBut I believe the requirement for this is for replicas to share the repositories[3] first. Otherwise we would be scaling replicas that \"won\u0027t have the latest version of the repositories\", as you put it.\n\n\n\n\n\u003e \n\u003e \u003e [1] https://aws.amazon.com/about-aws/whats-new/2018/06/amazon-ecs-adds-daemon-scheduling/\n\n\n\n[1]https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html\n[2]https://bugs.chromium.org/p/gerrit/issues/detail?id\u003d13620\n[3]https://bugs.chromium.org/p/gerrit/issues/detail?id\u003d13619",
      "parentUuid": "90ff421e_43ed4ef0",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e5212982_e982cc2d",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-11-04T11:10:12Z",
      "side": 1,
      "message": "Compacting, by leaving only the Q\u0026As:\n\n\u003e \u003e If you needed resources for 5 containers, how 6 instances could have helped out?\n\u003e \n\u003e They wouldn\u0027t, of course, because you have EC2 instances that you would never be able to use (unless you start scaling).\n\nOK, so the 6 instances we had before were unneeded? or would have been useful to manage some spare capacity in case of restarts/upgrades?\n\n\u003e But you were able to decide if you wanted those 5 instances over 3 m4.xlarge or over 2 m4.2xlarge, for example.\n\nI don\u0027t believe we had the ability to mix instance types, but we had only one instance type parameter. But yes, you could have opted for less instances and more powerful instances types vs. more instances with less power.\n\nAnyway, I see now the limit of not being able to configure the number of instances anymore, which is a minus IMHO.\n\n\u003e \u003e I do not believe AWS can split a container across multiple EC2 instances, to provide more resources.\n\u003e \n\u003e The most granular component that can be deployed is not the container, it\u0027s the task.\n\u003e \n\u003e * ECS Instance -\u003e EC2 instance with an ecs-agent running on it.\n\u003e * Service -\u003e collection of Tasks\n\u003e * Task -\u003e collection of Containers (replica task for example is composed by gerrit/ssh/daemon)\n\nOh, that\u0027s not good then. You may actually want to have gerrit, ssh and the daemon potentially on different EC2 instances. I believe that is something to address as a follow-up.\n\n\u003e Whilst the service can span across multiple ECS Instances, the Task cannot and it is always deployed in the same ECS Instance.\n\nThanks for clarifying: that highlights the problem that the Git/SSH and Git/daemon would then impact on the Gerrit resources, which is bad.\nAs mentioned above, it can be addressed as a follow-up change.\n\n\u003e \u003e \u003e If you changed your gerrit specs to be higher however, you might need a cluster of 3, and so on.\n\u003e \u003e \u003e \n\u003e \u003e \u003e The number of instances in the cluster is a function of _needed resources_, not just of _number of instances_.\n\u003e \u003e \n\u003e \u003e I am not 100% convinced AWS can do that, also inside an ECS cluster.\n\u003e \u003e At the end of the day, ECS is just an orchestrator of Docker containers, and the minimum allocation is 1 container per instance, but won\u0027t be able to go beyond that. The maximum allocation instead would be all containers in a single instance.\n\u003e \n\u003e The minimum allocation is 1 _Task_ per instance, not 1 container.\n\u003e The most compact allocation is all _Services_ in a single instance (but as we have seen we cannot have this topology because tasks wouldn\u0027t be able to talk to each others via the NLB).\n\nSure, but my point is that if you have 1 task that requires more resources than the EC2 instance type you have, then having more instances won\u0027t help.\n\nIs that understanding correct?\n\n\u003e \u003e An ECS daemon would still need to be allocated in the cluster with some placement, correct?\n\u003e \u003e \n\u003e \u003e An AWS step function is just an orchestration of something, not really a computing entity whilst with the AWS lambdas, I\u0027m not 100% sure they are designed to run a long, CPU and memory intensive operation, like the JGit GC.\n\u003e \n\u003e As I was mentioning, I am not sure, I think there are different approaches, some of which do not need any additional allocation (SSM agent[1] already runs on Amazon Linux images, so it could be \"talked to\" without running extra components).\n\u003e Shall we discuss/brainstorm about this specific issue in the relevant issue ticket?[2]\n\nAgreed, we can take this discussion off-line.\n\nWe can just focus on the issue we need to address as part of this change: the regression on the number of instances, before configurable and now hardcoded to 1.\n\n\u003e Scaling for \"more horsepower\" for masters is something I don\u0027t get, masters only run gerrit masters and I am not convinced we need to run anything else alongside them (at least for now).\n\u003e \n\u003e Rolling upgrades is an interesting subject and you\u0027re right, it might fall into the same conversation.\n\u003e \n\u003e TBH, I was thinking something along the lines of\n\u003e - deploy a completely new green cluster (maintaining the data)\n\u003e - Switch traffic to green\n\u003e - delete blue cluster\n\nThat looks quite an overkill IMHO: ECS already manages blue/green deployments automatically. What I don\u0027t know is *IF* the maximum number of instances in the cluster needs to accommodate that or not.\n\n\u003e Were you thinking about scaling up the blue cluster and let old and new co-living together in the same cluster?\n\u003e \n\u003e P.S. Should I create a monorail ticket to address upgrades?\n\nNope, this is something ECS should do, not us. We don\u0027t want to reinvent the wheel, but integrate as much as possible with the native AWS ECS features.\n\nIf we don\u0027t use them, it\u0027s fine but we need to have a strong argument behind it.\n\n\u003e \u003e Nope, when you have replicas with ASG they need to share the repositories, otherwise when they scale up then won\u0027t have the latest version of the repositories.\n\u003e \n\u003e Exactly, they need to share the repositories, but they just don\u0027t do that at the moment.\n\u003e That\u0027s why I was asking \"What\u0027s the point of increasing the number of replicas _before we have an EFS to share across them?_\"\n\u003e \n\u003e I understand the benefit of scaling replicas _once_ they share repositories.\n\nSure, but my point is: what the point of removing the parameter for adding it back again tomorrow?\n\n\u003e \u003e \u003e What\u0027s the point of increasing the number of replicas before we have an EFS to share across them?\n\u003e \u003e \n\u003e \u003e Horizontal scalability, for managing peaks of incoming traffic.\n\u003e \n\u003e I understand why we need to scale replicas, of course.\n\u003e But I believe the requirement for this is for replicas to share the repositories[3] first. Otherwise we would be scaling replicas that \"won\u0027t have the latest version of the repositories\", as you put it.\n\nAck, but please see also my point of not removing something that you add back immediately afterwards.\n\n\u003e [1]https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html\n\u003e [2]https://bugs.chromium.org/p/gerrit/issues/detail?id\u003d13620\n\u003e [3]https://bugs.chromium.org/p/gerrit/issues/detail?id\u003d13619",
      "parentUuid": "9cef0b1d_9e8c529e",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "64eb7a92_120a44d5",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-11-04T14:11:05Z",
      "side": 1,
      "message": "\u003e Compacting, by leaving only the Q\u0026As:\n\u003e \n\u003e \u003e \u003e If you needed resources for 5 containers, how 6 instances could have helped out?\n\u003e \u003e \n\u003e \u003e They wouldn\u0027t, of course, because you have EC2 instances that you would never be able to use (unless you start scaling).\n\u003e \n\u003e OK, so the 6 instances we had before were unneeded? or would have been useful to manage some spare capacity in case of restarts/upgrades?\n\n\nI think they were needed to accommodate the wanted resources across the chosen instanceType:\n- raising RAM and CPU might have required to have more EC2 of type $instance-type.\n- increasing $instance-type might have allowed to have fewer EC2 to run the cluster.\n\nPerhaps restarts/upgrades will require to scale elastically (depending on how we decide to do it), but scaling masters ASG alone doesn\u0027t just give us the ability to upgrade.\n\nIf you think allowing master ASGs to scale will be useful as a preparation for upgrade strategies then we do so, but I don\u0027t have it clear in my mind how those upgrades will be carried out yet, so I am not sure if that is going to help.\n\nI do believe we need a ticket to capture what\u0027s required to perform cluster upgrades (more on this later).\n\n\n\n\n\u003e \n\u003e \u003e But you were able to decide if you wanted those 5 instances over 3 m4.xlarge or over 2 m4.2xlarge, for example.\n\u003e \n\u003e I don\u0027t believe we had the ability to mix instance types, but we had only one instance type parameter. But yes, you could have opted for less instances and more powerful instances types vs. more instances with less power.\n\u003e \n\u003e Anyway, I see now the limit of not being able to configure the number of \ninstances anymore, which is a minus IMHO.\n\nThese are the components we have in dual-master: master, haproxy, replica.\nThey cannot share the same EC2 instance, otherwise failing to connect to each other (that\u0027s why we separated replicas and haproxy into their own ASG and why now we are doing this with masters).\n\nAs a consequence of the above we now have 3 separate ASGs.\n\nIn the past everything was in the same ASG, so it made sense to be able to scale (because even if only one component needed, then the entire ASG needed to scale), but now that we have separate ASG we should decide which ones should scale and which ones shouldn\u0027t.\n\n- haproxy: it is already able to scale up up to a configurable number.\n- replicas: should be able to scale up, but it is not useful until we have an EFS, so we should do that first.\n- master: I don\u0027t see what it would mean to allow to have 3 or 4 master1s. If it\u0027s just for upgrading then we might need to *temporarily* allow scaling (up to 2 only?), but I think this should be dealt with when implementing cluster upgrades policies.\n\n\n\n\n\n\n\n\n\n\u003e \n\u003e \u003e \u003e I do not believe AWS can split a container across multiple EC2 instances, to provide more resources.\n\u003e \u003e \n\u003e \u003e The most granular component that can be deployed is not the container, it\u0027s the task.\n\u003e \u003e \n\u003e \u003e * ECS Instance -\u003e EC2 instance with an ecs-agent running on it.\n\u003e \u003e * Service -\u003e collection of Tasks\n\u003e \u003e * Task -\u003e collection of Containers (replica task for example is composed by gerrit/ssh/daemon)\n\u003e \n\u003e Oh, that\u0027s not good then. You may actually want to have gerrit, ssh and the daemon potentially on different EC2 instances. I believe that is something to address as a follow-up.\n\nHow can you separate the Git and SSH Daemon from the replica?\nGit and SSH daemons are the only means for which replication data can get to the replica EBS volume, isn\u0027t?\n\n\n\n\n\n\n\n\n\u003e \n\u003e \u003e Whilst the service can span across multiple ECS Instances, the Task cannot and it is always deployed in the same ECS Instance.\n\u003e \n\u003e Thanks for clarifying: that highlights the problem that the Git/SSH and Git/daemon would then impact on the Gerrit resources, which is bad.\n\u003e As mentioned above, it can be addressed as a follow-up change.\n\n\nSee above, how can you separate them from the replica?\n\n\n\n\n\n\n\n\n\u003e \n\u003e \u003e \u003e \u003e If you changed your gerrit specs to be higher however, you might need a cluster of 3, and so on.\n\u003e \u003e \u003e \u003e \n\u003e \u003e \u003e \u003e The number of instances in the cluster is a function of _needed resources_, not just of _number of instances_.\n\u003e \u003e \u003e \n\u003e \u003e \u003e I am not 100% convinced AWS can do that, also inside an ECS cluster.\n\u003e \u003e \u003e At the end of the day, ECS is just an orchestrator of Docker containers, and the minimum allocation is 1 container per instance, but won\u0027t be able to go beyond that. The maximum allocation instead would be all containers in a single instance.\n\u003e \u003e \n\u003e \u003e The minimum allocation is 1 _Task_ per instance, not 1 container.\n\u003e \u003e The most compact allocation is all _Services_ in a single instance (but as we have seen we cannot have this topology because tasks wouldn\u0027t be able to talk to each others via the NLB).\n\u003e \n\u003e Sure, but my point is that if you have 1 task that requires more resources than the EC2 instance type you have, then having more instances won\u0027t help.\n\u003e \n\u003e Is that understanding correct?\n\nYes, if you wanted to deploy one task that required more resources than the EC2 instance type, you will need to increase the instance-type to allow that task to be deployed.\n\nBut this is always the case right? you need to run the task on an EC2 instance that _can_ run it.\n\n\n\n\n\n\n\u003e \n\u003e \u003e \u003e An ECS daemon would still need to be allocated in the cluster with some placement, correct?\n\u003e \u003e \u003e \n\u003e \u003e \u003e An AWS step function is just an orchestration of something, not really a computing entity whilst with the AWS lambdas, I\u0027m not 100% sure they are designed to run a long, CPU and memory intensive operation, like the JGit GC.\n\u003e \u003e \n\u003e \u003e As I was mentioning, I am not sure, I think there are different approaches, some of which do not need any additional allocation (SSM agent[1] already runs on Amazon Linux images, so it could be \"talked to\" without running extra components).\n\u003e \u003e Shall we discuss/brainstorm about this specific issue in the relevant issue ticket?[2]\n\u003e \n\u003e Agreed, we can take this discussion off-line.\n\u003e \n\u003e We can just focus on the issue we need to address as part of this change: the regression on the number of instances, before configurable and now hardcoded to 1.\n\u003e \n\nSee my reply above, I believe we can still configure what is needed (i.e. haproxy, replicas in the future). We never needed to have master on autoscaling groups greater than 1, imho.\n\n\n\n\n\n\u003e \u003e Scaling for \"more horsepower\" for masters is something I don\u0027t get, masters only run gerrit masters and I am not convinced we need to run anything else alongside them (at least for now).\n\u003e \u003e \n\u003e \u003e Rolling upgrades is an interesting subject and you\u0027re right, it might fall into the same conversation.\n\u003e \u003e \n\u003e \u003e TBH, I was thinking something along the lines of\n\u003e \u003e - deploy a completely new green cluster (maintaining the data)\n\u003e \u003e - Switch traffic to green\n\u003e \u003e - delete blue cluster\n\u003e \n\u003e That looks quite an overkill IMHO: ECS already manages blue/green deployments automatically. What I don\u0027t know is *IF* the maximum number of instances in the cluster needs to accommodate that or not.\n\u003e \n\u003e \u003e Were you thinking about scaling up the blue cluster and let old and new co-living together in the same cluster?\n\u003e \u003e \n\u003e \u003e P.S. Should I create a monorail ticket to address upgrades?\n\u003e \n\u003e Nope, this is something ECS should do, not us. We don\u0027t want to reinvent the wheel, but integrate as much as possible with the native AWS ECS features.\n\u003e \n\u003e If we don\u0027t use them, it\u0027s fine but we need to have a strong argument behind it.\n\nI think we should use ECS to do blue/green deployments, absolutely.\nBut I believe, that this requires some work:\n\nSome examples:\n- there\u0027s no \"make upgrade\" in aws gerrit. you can only trigger a creation or deletion.\n- If you were to upgrade loadbalancers you would need to point route53 to them (or add/remove listeners)\n- We would need to drain connection and then switch the DNS from green to blue.\n- ...\n\nIf you wanted to trigger a cluster update today how would you do it? \n \n\n\n\n\n\n\u003e \n\u003e \u003e \u003e Nope, when you have replicas with ASG they need to share the repositories, otherwise when they scale up then won\u0027t have the latest version of the repositories.\n\u003e \u003e \n\u003e \u003e Exactly, they need to share the repositories, but they just don\u0027t do that at the moment.\n\u003e \u003e That\u0027s why I was asking \"What\u0027s the point of increasing the number of replicas _before we have an EFS to share across them?_\"\n\u003e \u003e \n\u003e \u003e I understand the benefit of scaling replicas _once_ they share repositories.\n\u003e \n\u003e Sure, but my point is: what the point of removing the parameter for adding it back again tomorrow?\n\n\nThis CR is not removing any scaling abilities from replicas.\nThat\u0027s already set at 1, from the previous change we merged, which I think was the correct thing to do, given they don\u0027t share any EFS.\n\n\n\n\n\n\u003e \n\u003e \u003e \u003e \u003e What\u0027s the point of increasing the number of replicas before we have an EFS to share across them?\n\u003e \u003e \u003e \n\u003e \u003e \u003e Horizontal scalability, for managing peaks of incoming traffic.\n\u003e \u003e \n\u003e \u003e I understand why we need to scale replicas, of course.\n\u003e \u003e But I believe the requirement for this is for replicas to share the repositories[3] first. Otherwise we would be scaling replicas that \"won\u0027t have the latest version of the repositories\", as you put it.\n\u003e \n\u003e Ack, but please see also my point of not removing something that you add back immediately afterwards.\n\nWe don\u0027t remove scalability from replicas in this CR.\n\n\n\n\n\n\n\u003e \n\u003e \u003e [1]https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html\n\u003e \u003e [2]https://bugs.chromium.org/p/gerrit/issues/detail?id\u003d13620\n\u003e \u003e [3]https://bugs.chromium.org/p/gerrit/issues/detail?id\u003d13619",
      "parentUuid": "e5212982_e982cc2d",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "77ab64e3_f5968152",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-11-05T09:01:23Z",
      "side": 1,
      "message": "\u003e \u003e Compacting, by leaving only the Q\u0026As:\n\u003e \u003e \n\u003e \u003e \u003e \u003e If you needed resources for 5 containers, how 6 instances could have helped out?\n\u003e \u003e \u003e \n\u003e \u003e \u003e They wouldn\u0027t, of course, because you have EC2 instances that you would never be able to use (unless you start scaling).\n\u003e \u003e \n\u003e \u003e OK, so the 6 instances we had before were unneeded? or would have been useful to manage some spare capacity in case of restarts/upgrades?\n\u003e \n\u003e \n\u003e I think they were needed to accommodate the wanted resources across the chosen instanceType:\n\u003e - raising RAM and CPU might have required to have more EC2 of type $instance-type.\n\u003e - increasing $instance-type might have allowed to have fewer EC2 to run the cluster.\n\u003e \n\u003e Perhaps restarts/upgrades will require to scale elastically (depending on how we decide to do it), but scaling masters ASG alone doesn\u0027t just give us the ability to upgrade.\n\u003e \n\u003e If you think allowing master ASGs to scale will be useful as a preparation for upgrade strategies then we do so, but I don\u0027t have it clear in my mind how those upgrades will be carried out yet, so I am not sure if that is going to help.\n\u003e \n\u003e I do believe we need a ticket to capture what\u0027s required to perform cluster upgrades (more on this later).\n\nMajor upgrades: that is premature for now, as we don\u0027t have fully configured and working system yet.\n\nMinor upgrade: why need first to demonstrate that ECS upgrades aren\u0027t suitable, and then raise the issue after that, with the details of why they are not working for us.\n\n[...]\n\u003e \n\u003e In the past everything was in the same ASG, so it made sense to be able to scale (because even if only one component needed, then the entire ASG needed to scale), but now that we have separate ASG we should decide which ones should scale and which ones shouldn\u0027t.\n\u003e \n\u003e - haproxy: it is already able to scale up up to a configurable number.\n\u003e - replicas: should be able to scale up, but it is not useful until we have an EFS, so we should do that first.\n\u003e - master: I don\u0027t see what it would mean to allow to have 3 or 4 master1s. If it\u0027s just for upgrading then we might need to *temporarily* allow scaling (up to 2 only?), but I think this should be dealt with when implementing cluster upgrades policies.\n\nI am fine in hardcoding the ASG fo the masters to 1, assuming that isn\u0027t blocking the normal ECS update process. Can you verify that?\n\nIt should be straightforward: just change something of the image (e.g. config) and then update the task definition (only the SHA1 of the container\u0027s image).\n\n\u003e \u003e \u003e \u003e I do not believe AWS can split a container across multiple EC2 instances, to provide more resources.\n\u003e \u003e \u003e \n\u003e \u003e \u003e The most granular component that can be deployed is not the container, it\u0027s the task.\n\u003e \u003e \u003e \n\u003e \u003e \u003e * ECS Instance -\u003e EC2 instance with an ecs-agent running on it.\n\u003e \u003e \u003e * Service -\u003e collection of Tasks\n\u003e \u003e \u003e * Task -\u003e collection of Containers (replica task for example is composed by gerrit/ssh/daemon)\n\u003e \u003e \n\u003e \u003e Oh, that\u0027s not good then. You may actually want to have gerrit, ssh and the daemon potentially on different EC2 instances. I believe that is something to address as a follow-up.\n\u003e \n\u003e How can you separate the Git and SSH Daemon from the replica?\n\u003e Git and SSH daemons are the only means for which replication data can get to the replica EBS volume, isn\u0027t?\n\nDifferent tasks can have placement constraints, isn\u0027t it?\nSo it should be feasible.\n\nAlso, bear in kind that for Gerrit replicas you want to have ASG with a shared EFS, otherwise there is no ability to scale.\n\n\u003e \u003e \u003e Whilst the service can span across multiple ECS Instances, the Task cannot and it is always deployed in the same ECS Instance.\n\u003e \u003e \n\u003e \u003e Thanks for clarifying: that highlights the problem that the Git/SSH and Git/daemon would then impact on the Gerrit resources, which is bad.\n\u003e \u003e As mentioned above, it can be addressed as a follow-up change.\n\u003e \n\u003e \n\u003e See above, how can you separate them from the replica?\n\nSee the answer to that above.\n\n[...]\n\u003e \u003e Sure, but my point is that if you have 1 task that requires more resources than the EC2 instance type you have, then having more instances won\u0027t help.\n\u003e \u003e \n\u003e \u003e Is that understanding correct?\n\u003e \n\u003e Yes, if you wanted to deploy one task that required more resources than the EC2 instance type, you will need to increase the instance-type to allow that task to be deployed.\n\u003e \n\u003e But this is always the case right? you need to run the task on an EC2 instance that _can_ run it.\n\nYep, exactly. So, also before the \u00276\u0027 value was incorrect, as we could have not possibly used it.\n\n\n\u003e See my reply above, I believe we can still configure what is needed (i.e. haproxy, replicas in the future). We never needed to have master on autoscaling groups greater than 1, imho.\n\nSure, just verify the upgrade process and where to put the JGit GC task. Are you planning another ASG for that?\n\n[...]\n\u003e \u003e Nope, this is something ECS should do, not us. We don\u0027t want to reinvent the wheel, but integrate as much as possible with the native AWS ECS features.\n\u003e \u003e \n\u003e \u003e If we don\u0027t use them, it\u0027s fine but we need to have a strong argument behind it.\n\u003e \n\u003e I think we should use ECS to do blue/green deployments, absolutely.\n\u003e But I believe, that this requires some work:\n\u003e \n\u003e Some examples:\n\u003e - there\u0027s no \"make upgrade\" in aws gerrit. you can only trigger a creation or deletion.\n\u003e - If you were to upgrade loadbalancers you would need to point route53 to them (or add/remove listeners)\n\u003e - We would need to drain connection and then switch the DNS from green to blue.\n\u003e - ...\n\nAre you sure that ECS doesn\u0027t do that for us? Have you tried?\n\n \n\u003e If you wanted to trigger a cluster update today how would you do it? \n\nI do not mean a major upgrade, but the minor upgrade like a configuration change or a minor fix upgrade (e.g. Gerrit 3.2.3 to 3.2.4)\n\n[...]\n\u003e \u003e Sure, but my point is: what the point of removing the parameter for adding it back again tomorrow?\n\u003e \n\u003e \n\u003e This CR is not removing any scaling abilities from replicas.\n\u003e That\u0027s already set at 1, from the previous change we merged, which I think was the correct thing to do, given they don\u0027t share any EFS.\n\nLet me re-check, I thought the master ASG was still set to 1 hardcoded.\n\n\u003e \u003e Ack, but please see also my point of not removing something that you add back immediately afterwards.\n\u003e \n\u003e We don\u0027t remove scalability from replicas in this CR.\n\nI\u0027ll double-check for the master ASG.\n\n\u003e \u003e \u003e [1]https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html\n\u003e \u003e \u003e [2]https://bugs.chromium.org/p/gerrit/issues/detail?id\u003d13620\n\u003e \u003e \u003e [3]https://bugs.chromium.org/p/gerrit/issues/detail?id\u003d13619",
      "parentUuid": "64eb7a92_120a44d5",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b0121064_5c9736c1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-11-05T17:00:21Z",
      "side": 1,
      "message": "\u003e \u003e \u003e Compacting, by leaving only the Q\u0026As:\n\u003e \u003e \u003e \n\u003e \u003e \u003e \u003e \u003e If you needed resources for 5 containers, how 6 instances could have helped out?\n\u003e \u003e \u003e \u003e \n\u003e \u003e \u003e \u003e They wouldn\u0027t, of course, because you have EC2 instances that you would never be able to use (unless you start scaling).\n\u003e \u003e \u003e \n\u003e \u003e \u003e OK, so the 6 instances we had before were unneeded? or would have been useful to manage some spare capacity in case of restarts/upgrades?\n\u003e \u003e \n\u003e \u003e \n\u003e \u003e I think they were needed to accommodate the wanted resources across the chosen instanceType:\n\u003e \u003e - raising RAM and CPU might have required to have more EC2 of type $instance-type.\n\u003e \u003e - increasing $instance-type might have allowed to have fewer EC2 to run the cluster.\n\u003e \u003e \n\u003e \u003e Perhaps restarts/upgrades will require to scale elastically (depending on how we decide to do it), but scaling masters ASG alone doesn\u0027t just give us the ability to upgrade.\n\u003e \u003e \n\u003e \u003e If you think allowing master ASGs to scale will be useful as a preparation for upgrade strategies then we do so, but I don\u0027t have it clear in my mind how those upgrades will be carried out yet, so I am not sure if that is going to help.\n\u003e \u003e \n\u003e \u003e I do believe we need a ticket to capture what\u0027s required to perform cluster upgrades (more on this later).\n\u003e \n\u003e Major upgrades: that is premature for now, as we don\u0027t have fully configured and working system yet.\n\u003e \n\u003e Minor upgrade: why need first to demonstrate that ECS upgrades aren\u0027t suitable, and then raise the issue after that, with the details of why they are not working for us.\n\nAck\n\n\u003e \n\u003e [...]\n\u003e \u003e \n\u003e \u003e In the past everything was in the same ASG, so it made sense to be able to scale (because even if only one component needed, then the entire ASG needed to scale), but now that we have separate ASG we should decide which ones should scale and which ones shouldn\u0027t.\n\u003e \u003e \n\u003e \u003e - haproxy: it is already able to scale up up to a configurable number.\n\u003e \u003e - replicas: should be able to scale up, but it is not useful until we have an EFS, so we should do that first.\n\u003e \u003e - master: I don\u0027t see what it would mean to allow to have 3 or 4 master1s. If it\u0027s just for upgrading then we might need to *temporarily* allow scaling (up to 2 only?), but I think this should be dealt with when implementing cluster upgrades policies.\n\u003e \n\u003e I am fine in hardcoding the ASG fo the masters to 1, assuming that isn\u0027t blocking the normal ECS update process. Can you verify that?\n\u003e \n\u003e It should be straightforward: just change something of the image (e.g. config) and then update the task definition (only the SHA1 of the container\u0027s image).\n\nSure, I will give it a try\n\n\u003e \n\u003e \u003e \u003e \u003e \u003e I do not believe AWS can split a container across multiple EC2 instances, to provide more resources.\n\u003e \u003e \u003e \u003e \n\u003e \u003e \u003e \u003e The most granular component that can be deployed is not the container, it\u0027s the task.\n\u003e \u003e \u003e \u003e \n\u003e \u003e \u003e \u003e * ECS Instance -\u003e EC2 instance with an ecs-agent running on it.\n\u003e \u003e \u003e \u003e * Service -\u003e collection of Tasks\n\u003e \u003e \u003e \u003e * Task -\u003e collection of Containers (replica task for example is composed by gerrit/ssh/daemon)\n\u003e \u003e \u003e \n\u003e \u003e \u003e Oh, that\u0027s not good then. You may actually want to have gerrit, ssh and the daemon potentially on different EC2 instances. I believe that is something to address as a follow-up.\n\u003e \u003e \n\u003e \u003e How can you separate the Git and SSH Daemon from the replica?\n\u003e \u003e Git and SSH daemons are the only means for which replication data can get to the replica EBS volume, isn\u0027t?\n\u003e \n\u003e Different tasks can have placement constraints, isn\u0027t it?\n\u003e So it should be feasible.\n\nUntil we switch replicas to EFS, SSH and Git daemon should *always* be placed together with the Gerrit replicas.\n\nI agree, after switching to EFS we should have a \u0027replica-replication-service\u0027, in the same way we have a \u0027replication-service\u0027 for masters. A that point, we can remove the additional those side-car containers from the replica task definition.\n\n\u003e \n\u003e Also, bear in kind that for Gerrit replicas you want to have ASG with a shared EFS, otherwise there is no ability to scale.\n\nYep, there\u0027s an issue for that[1]\n\n\u003e \n\u003e \u003e \u003e \u003e Whilst the service can span across multiple ECS Instances, the Task cannot and it is always deployed in the same ECS Instance.\n\u003e \u003e \u003e \n\u003e \u003e \u003e Thanks for clarifying: that highlights the problem that the Git/SSH and Git/daemon would then impact on the Gerrit resources, which is bad.\n\u003e \u003e \u003e As mentioned above, it can be addressed as a follow-up change.\n\u003e \u003e \n\u003e \u003e \n\u003e \u003e See above, how can you separate them from the replica?\n\u003e \n\u003e See the answer to that above.\n\nAck\n\n\u003e \n\u003e [...]\n\u003e \u003e \u003e Sure, but my point is that if you have 1 task that requires more resources than the EC2 instance type you have, then having more instances won\u0027t help.\n\u003e \u003e \u003e \n\u003e \u003e \u003e Is that understanding correct?\n\u003e \u003e \n\u003e \u003e Yes, if you wanted to deploy one task that required more resources than the EC2 instance type, you will need to increase the instance-type to allow that task to be deployed.\n\u003e \u003e \n\u003e \u003e But this is always the case right? you need to run the task on an EC2 instance that _can_ run it.\n\u003e \n\u003e Yep, exactly. So, also before the \u00276\u0027 value was incorrect, as we could have not possibly used it.\n\nWe could have used it to scale ha-proxies, or replication-services, or (unusable) replicas, but not for masters, I don\u0027t think so.\n\nI am going to check minor upgrade before and after this change though and see if there\u0027s any regression.\n\n\u003e \n\u003e \n\u003e \u003e See my reply above, I believe we can still configure what is needed (i.e. haproxy, replicas in the future). We never needed to have master on autoscaling groups greater than 1, imho.\n\u003e \n\u003e Sure, just verify the upgrade process and where to put the JGit GC task. Are you planning another ASG for that?\n\nJgit needs to have access to the EFS so I would just have it running on the same EC2 instances as masters (same ASG).\nIt could be a DAEMON task running alongside master1, or completely a new task running anywhere on the EC2 instance which is a member of the master ASG.\nI don\u0027t think we need a new ASG for jgit.\n\nWDYT?\n\n\n\u003e \n\u003e [...]\n\u003e \u003e \u003e Nope, this is something ECS should do, not us. We don\u0027t want to reinvent the wheel, but integrate as much as possible with the native AWS ECS features.\n\u003e \u003e \u003e \n\u003e \u003e \u003e If we don\u0027t use them, it\u0027s fine but we need to have a strong argument behind it.\n\u003e \u003e \n\u003e \u003e I think we should use ECS to do blue/green deployments, absolutely.\n\u003e \u003e But I believe, that this requires some work:\n\u003e \u003e \n\u003e \u003e Some examples:\n\u003e \u003e - there\u0027s no \"make upgrade\" in aws gerrit. you can only trigger a creation or deletion.\n\u003e \u003e - If you were to upgrade loadbalancers you would need to point route53 to them (or add/remove listeners)\n\u003e \u003e - We would need to drain connection and then switch the DNS from green to blue.\n\u003e \u003e - ...\n\u003e \n\u003e Are you sure that ECS doesn\u0027t do that for us? Have you tried?\n\nThe association between Route53 DNS entries and NLBs is done programmatically by the aws-gerrit recipe not automatically by ECS[2] if we were to create a new NLB the association would also need to be done by our cloudformation script.\n\n\n\u003e \n\u003e  \n\u003e \u003e If you wanted to trigger a cluster update today how would you do it? \n\u003e \n\u003e I do not mean a major upgrade, but the minor upgrade like a configuration change or a minor fix upgrade (e.g. Gerrit 3.2.3 to 3.2.4)\n\nI see, but this still needs to be done in my opinion.\nThis is an upgrade attempt on aws-gerrit *master*, done before this change (current master):\n\nI changed gerrit configuration from the aws-gerrit checkout.\nthen pushed a new image for it:\n\n```\nmake AWS_REGION\u003dus-east-1 AWS_PREFIX\u003dtony gerrit-publish \n```\n\nA new image is now registered in ECR\naws-gerrit/gerrit:3.2.3-646910c2cb3e09f44ca5\n\nTrying to deploy the new master:\n\n```\nmake AWS_REGION\u003dus-east-1 AWS_PREFIX\u003dtony IMAGE_TAG\u003d3.2.3-646910c2cb3e09f44ca5 service-master-1\n```\n\nFails with:\n\n```An error occurred (AlreadyExistsException) when calling the CreateStack operation: Stack [tony-service-master-1] already exists\nmake: *** [service-master-1] Error 254\n```\n\nWe cannot do any updates, just creations or deletions.\n\nQ: First monorail issue needed?\n\nIf I manually change the Makefile to allow updates (update-stacks, instead of create-stack), the master1 stacks goes into UPDATE_IN_PROGRESS status.\n\nThe master1 service is created on the same instance as the master2: this makes sense, because on master1 the _current_ service is still running so there would be a port collision.\n\nHaving said that, the new server never becomes \"healthy\".\n\nTask failed ELB health checks in (target-group arn:aws:elasticloadbalancing:us-east-1:117385740707:targetgroup/tony-HTTPT-11G7BAOW4B2NQ/d0cbb9d7a65794cd)\n\nunfortunately, I am not sure why yet, everything seems fine if I query it directly.\n\n\nQ2: Second monorail needed?\n\nThe take-home lesson however is that if we only had 1 instance for master1, the new task would have no placement: we need 2 instances for upgrading master1 and master2.\n\nQ3: I can raise the max ASG for master1 and master2 to 2, as part of this CR.\n\n\nECS however does not scale automatically the EC2 instances when needed[5]: to do that, Amazon ECS cluster auto scaling[3] needs to be used and Capacity providers[4].\n\nQ4: Third monorail needed?\n\nWDYT?\n\n\n\u003e \n\u003e [...]\n\u003e \u003e \u003e Sure, but my point is: what the point of removing the parameter for adding it back again tomorrow?\n\u003e \u003e \n\u003e \u003e \n\u003e \u003e This CR is not removing any scaling abilities from replicas.\n\u003e \u003e That\u0027s already set at 1, from the previous change we merged, which I think was the correct thing to do, given they don\u0027t share any EFS.\n\u003e \n\u003e Let me re-check, I thought the master ASG was still set to 1 hardcoded.\n\u003e \n\u003e \u003e \u003e Ack, but please see also my point of not removing something that you add back immediately afterwards.\n\u003e \u003e \n\u003e \u003e We don\u0027t remove scalability from replicas in this CR.\n\u003e \n\u003e I\u0027ll double-check for the master ASG.\n\u003e \n[1]https://bugs.chromium.org/p/gerrit/issues/detail?id\u003d13619\n[2]https://gerrit.googlesource.com/aws-gerrit/+/refs/heads/master/dual-master/cf-dns-route.yml#36\n[3]https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-auto-scaling.html\n[4]https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-capacity-providers.html\n[5]https://aws.amazon.com/blogs/containers/deep-dive-on-amazon-ecs-cluster-auto-scaling/",
      "parentUuid": "77ab64e3_f5968152",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "782467f1_cca69423",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-11-05T17:05:08Z",
      "side": 1,
      "message": "I pressed enter too early, Q2 has already an answer:\neventually the new master becomes healthy ðŸ˜Š",
      "parentUuid": "b0121064_5c9736c1",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9f2dd4a2_926754d4",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-11-05T21:56:51Z",
      "side": 1,
      "message": "I checked the ECS service update:\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-service.html\n\nIt looks like it is possible to update a service, I am not sure why it didn\u0027t work for you.\n\nIf we hardcode the number of instances to 1, we force the admin with the choice of the update type to \"minimum healthy percent \u003d 0\", which is a regression to what he could have done before.\n\nFrom that perspective, this change represent a regression IMHO, because before he could have chosen \"minimum healthy percent \u003d 100\" and ECS would have done a blue/green deployment, making sure to drain the incoming connections.",
      "parentUuid": "782467f1_cca69423",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d792f516_f48b7086",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-11-06T08:35:26Z",
      "side": 1,
      "message": "\u003e I checked the ECS service update:\n\u003e https://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-service.html\n\u003e \n\u003e It looks like it is possible to update a service, I am not sure why it didn\u0027t work for you.\n\nWhat do you mean? It actually did work.\n\n\"eventually the new master becomes healthy ðŸ˜Š\"\n\nTo perform upgrades from aws-gerrit however some changes are needed (see below).\n\n\u003e \n\u003e If we hardcode the number of instances to 1, we force the admin with the choice of the update type to \"minimum healthy percent \u003d 0\", which is a regression to what he could have done before.\n\nAgreed, that was one of my points above.\n\n\u003e \n\u003e From that perspective, this change represent a regression IMHO, because before he could have chosen \"minimum healthy percent \u003d 100\" and ECS would have done a blue/green deployment, making sure to drain the incoming connections.\n\nLet me recompact my update above.\nUpdating gerrit instances does work, but there are some changes that are required to achieve so:\n\n1. We cannot do any updates, just creations or deletions. The Makefiles need to expose update-\u003cservice\u003e commands to issue updates, via update-stack.\n\n2. I will raise the max ASG for master1 and master2 to N, as part of this CR, to allow upgrades in the future.\n\n3. ECS does not scale automatically the EC2 instances when needed[1], so having an increased maxSize for the ASG is not going to help much. To do that, Amazon ECS cluster auto scaling[3] needs to be used and Capacity providers[2].\n\nI will address 2 as part of this CR, in preparation for updates, but to _acutally_ do updates I think we need at least 1 and 3.\n\nWDYT?\n\n\n[1]https://aws.amazon.com/blogs/containers/deep-dive-on-amazon-ecs-cluster-auto-scaling/\n[2]https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-capacity-providers.html",
      "parentUuid": "9f2dd4a2_926754d4",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d3345d98_3b85ec6d",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-11-06T08:56:32Z",
      "side": 1,
      "message": "\u003e \u003e I checked the ECS service update:\n\u003e \u003e https://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-service.html\n\u003e \u003e \n\u003e \u003e It looks like it is possible to update a service, I am not sure why it didn\u0027t work for you.\n\u003e \n\u003e What do you mean? It actually did work.\n\u003e \n\u003e \"eventually the new master becomes healthy ðŸ˜Š\"\n\u003e \n\u003e To perform upgrades from aws-gerrit however some changes are needed (see below).\n\nCool, how did ECS managed to start the second master if there was no capacity?\nWe could have a 30\u0027 joint session today so that you can show me :-)\n\nBut if the upgrade works and we have a plan for the JGit GC, I\u0027m fine with it.\n\n\u003e \u003e \n\u003e \u003e If we hardcode the number of instances to 1, we force the admin with the choice of the update type to \"minimum healthy percent \u003d 0\", which is a regression to what he could have done before.\n\u003e \n\u003e Agreed, that was one of my points above.\n\nOK, let\u0027s try to do the task update with the current master and then with this change. If the behaviour is consistent, I\u0027m good :-)\n\n\u003e \u003e From that perspective, this change represent a regression IMHO, because before he could have chosen \"minimum healthy percent \u003d 100\" and ECS would have done a blue/green deployment, making sure to drain the incoming connections.\n\u003e \n\u003e Let me recompact my update above.\n\u003e Updating gerrit instances does work, but there are some changes that are required to achieve so:\n\u003e \n\u003e 1. We cannot do any updates, just creations or deletions. The Makefiles need to expose update-\u003cservice\u003e commands to issue updates, via update-stack.\n\nI believe you can also update with the ECS web console, isn\u0027t it?\n\n\u003e 2. I will raise the max ASG for master1 and master2 to N, as part of this CR, to allow upgrades in the future.\n\u003e \n\u003e 3. ECS does not scale automatically the EC2 instances when needed[1], so having an increased maxSize for the ASG is not going to help much. To do that, Amazon ECS cluster auto scaling[3] needs to be used and Capacity providers[2].\n\nGood catch. We definitely need a ticket to address that.\nSounds we have a plan :-)\n\nLuca.\n\n\u003e \n\u003e \n\u003e [1]https://aws.amazon.com/blogs/containers/deep-dive-on-amazon-ecs-cluster-auto-scaling/\n\u003e [2]https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-capacity-providers.html",
      "parentUuid": "d792f516_f48b7086",
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "349b6ca9_de21b145",
        "filename": "common-templates/cf-master-asg.yml",
        "patchSetId": 6
      },
      "lineNbr": 54,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-10-29T15:59:21Z",
      "side": 1,
      "message": "Should this be a parameter of the template?\n\nP.S. It was before a 1 to 6 ASG, whilst now it is just 1 instance.",
      "range": {
        "startLine": 52,
        "startChar": 0,
        "endLine": 54,
        "endChar": 26
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "f956ee3e_49aca5cb",
        "filename": "common-templates/cf-master-asg.yml",
        "patchSetId": 6
      },
      "lineNbr": 54,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-10-29T16:48:09Z",
      "side": 1,
      "message": "See my reply above.",
      "parentUuid": "349b6ca9_de21b145",
      "range": {
        "startLine": 52,
        "startChar": 0,
        "endLine": 54,
        "endChar": 26
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "12db68ce_39cc55b4",
        "filename": "common-templates/cf-master-asg.yml",
        "patchSetId": 6
      },
      "lineNbr": 54,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-10-29T17:16:35Z",
      "side": 1,
      "message": "Answered.",
      "parentUuid": "f956ee3e_49aca5cb",
      "range": {
        "startLine": 52,
        "startChar": 0,
        "endLine": 54,
        "endChar": 26
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "9712b62e_7512880f",
        "filename": "common-templates/cf-master-asg.yml",
        "patchSetId": 6
      },
      "lineNbr": 54,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-10-29T17:57:33Z",
      "side": 1,
      "message": "Ack",
      "parentUuid": "12db68ce_39cc55b4",
      "range": {
        "startLine": 52,
        "startChar": 0,
        "endLine": 54,
        "endChar": 26
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "5dd8aae3_d6213aaa",
        "filename": "common-templates/cf-master-asg.yml",
        "patchSetId": 6
      },
      "lineNbr": 54,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-10-29T17:57:33Z",
      "side": 1,
      "message": "Ack",
      "parentUuid": "12db68ce_39cc55b4",
      "range": {
        "startLine": 52,
        "startChar": 0,
        "endLine": 54,
        "endChar": 26
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "65cdbb2f_a9ee244e",
        "filename": "common-templates/cf-master-asg.yml",
        "patchSetId": 6
      },
      "lineNbr": 54,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-10-30T23:37:03Z",
      "side": 1,
      "message": "Forgot to push your changes?",
      "parentUuid": "9712b62e_7512880f",
      "range": {
        "startLine": 52,
        "startChar": 0,
        "endLine": 54,
        "endChar": 26
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c11b44d8_c38ba9e2",
        "filename": "common-templates/cf-master-asg.yml",
        "patchSetId": 6
      },
      "lineNbr": 54,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-11-02T10:06:23Z",
      "side": 1,
      "message": "oh yes, I had forgotten to push the commit message change, please refer to my reply for the discussion about scaling master nodes.",
      "parentUuid": "65cdbb2f_a9ee244e",
      "range": {
        "startLine": 52,
        "startChar": 0,
        "endLine": 54,
        "endChar": 26
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "13ba35a6_4b5563cc",
        "filename": "common-templates/cf-master-asg.yml",
        "patchSetId": 6
      },
      "lineNbr": 54,
      "author": {
        "id": 1072905
      },
      "writtenOn": "2020-11-02T13:01:27Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "c11b44d8_c38ba9e2",
      "range": {
        "startLine": 52,
        "startChar": 0,
        "endLine": 54,
        "endChar": 26
      },
      "revId": "cdb22d46accf5c11956d0202541526f5dbb4e2d4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    }
  ]
}